## Biological Interpretation {.page_break_before}

Introduction

Nearly every untargeted proteomics experiment will result in a list of proteins or peptides of interest which require further validation and biological interpretation.
In this section, we aim to present a concise overview of how proteomic data can be effectively contextualised and used to generate new hypotheses.
Firstly, it is typically infeasible to individually follow up on individual proteins one-by-one.
A smaller list can be prioritized by considering the level of significance and effect size.
For example, in a differential abundance analysis focusing efforts on proteins with small p-values (significance) and large abundance fold-changes (effect size).
When computational methods are used it is often useful to consider the whole list so that they are aware of the ranking of proteins, and the context of these values in a pathway. 
In this section, we consider a number of strategies to biologically interpret results.
The first is to consider functional enrichment through annotation databases.
These databases offer insights by examining the enrichment of certain functional annotations amongst the interesting proteins.
Secondly, one could consider other evolutionary, structurally or regulatory based methods to identify interpretation of the data.
To fully interpret analysis, it may be required to perform or examine other data such as data from biophysical, biochemical and alternative proteomic approaches.
Finally, the data can further be interpreted using multi-omic, native or clinical approaches.
Below we summarize these approaches and point out potential pitfalls with these methods.



1. Computational Enrichment terms:  KEGG, String, GO, GSEA, ORA, Reactome, diverse databases

Term enrichment analysis is performed to assess whether particular 'functional terms' are over-represented in a list of proteins (e.g. from a proteomics experiment) [@DOI:10.1007/978-1-4939-6783-4; @DOI:10.1016/j.ddtec.2021.06.007; @DOI:10.1152/physiolgenomics.00298.2007].
For example, after a differential abundance analysis, we may wish to examine whether there is any shared function amongst the proteins which were determined to have significant changes.
The simplest analysis to test whether this subset contains more of any particular functional terms than we would expect given the background of proteins.
For example, the Gene Ontology is split into the classes: Cellular Component, Molecular Function and Biological Function and we might be interested as to whether our proteins may be more likely to localize to a particular subcellular niche [@PMID:10802651].
The Cellular Component terms could give us a starting point if this might be the case, by examining if Cellular Component annotations are enriched. 

There are a number of databases and tools to perform such analysis, which can even be extended to examine whole pathways, networks, post-translational modification and literature representation.
For example, databses such as KEGG [@PMID:10592173], String [@PMID:33237311], Reactome [PMID:31691815] and PhosphoSitePlus [@PMID:30445427] can be used to test or annotate a list of proteins.
We refer to a number of articles on the topics, including tools, reviews and best-practice [@PMID:25430566, @PMID:33290552 @DOI:10.1371/journal.pcbi.1009935].
The main points from such analysis is that we can obtain an insight about protein function by looking at whether our list of proteins have similar or the same annotations.
A number of limitations should be taken into account for interpretation.
The first is that proteins that are more abundant are more likely to be studied, measured and examined in the literature.
Hence, abundant proteins will have more annotations than less abundant ones.
One key part of the analysis is also to correctly select the background set; that is, the universe of protein which our list is being compared against.
By including contaminates or proteins that are not expressed in our system within the list, the results may be unfaithful. 

We may also have access to our own curated set of annotations derived either computational or experimental.
One may be interested in seeing whether we have enrichment of these annotations amongst the differentially abundant proteins.
Our list of proteins could be divided into two groups: differentially abundant or not. These groups could be divided into whether they have a particular annotation: yes or no.
This information can be summarised in a two-by-two table, to which we can apply a statistical test to examine whether that annotation is enriched within our differentially abundant proteins.
One test that could be used is the hypergeometric test.

2. Computational approaches: Network analysis, Isoform correlation analysis, Alphafold, BLAST, protein language models

Additional computational analysis of a list of interesting proteins may uncover additional substructure, correlation or biologically useful hypothesis.
Building a network between the proteins based on the experiments performed, might be a useful approach to identify additional structure.
For example, co-expression network analysis can be used to build a network from these proteins [@10.3410/f.727201931.793589848].
In these networks, proteins are nodes and edges describe relationships between those proteins.
Network-specific methods can then be applied, such as community detection algorithms which could uncover clusters of proteins with shared functions [@DOI:10.1101/2020.06.21.163543. @DOI:https://doi.org/10.1016/j.physrep.2009.11.002].

One way the proteome generates complexity is through alternative-splicing, which results in protein isoforms [@https://doi.org/10.7554/eLife.34477].

Recently, a number of tools have been proposed to identify peptide isoforms that are quantitatively different across conditions by using a principle called peptide correlation analysis [@DOI:10.1101/2020.12.22.423928, @PMID:33325715].
The idea is that the quantitative behavior of peptides should match each other.
If there are subgroups that behave coherently within the group but not across groups suggest that peptide may have come from a different proteoform.
These approaches can be used to identify specific proteoforms that are functional across different conditions.

For many, a protein’s structure reveals important functional details [@PMID:18429251].
There are a plethora of approaches to predict a protein’s structure [@DOI:https://doi.org/10.1073/pnas.1821309116, @DOI:https://doi.org/10.1038/s41586-021-03819-2. @PMID:34282049]. 
Recently, AlphaFold and RosettaFold have become dominant methods for predicting protein structures with high resolution [@DOI:https://doi.org/10.1038/s41586-021-03819-2. @PMID:34282049]. 
If intrinsically disordered domains are of particular interest, methods explicitly designed for this task are recommended [@PMID:23203878].
Once a structure is obtained more elaborate computational methods might be useful such as docking or molecular dynamics [@PMID:21534921, @DOI:https://doi.org/10.2147/AABC.S70333].
These approaches can give insight into how protein or molecules fit together and the dynamics of a protein's structure (conformational heterogeneity).
A complete discussion of these topics is beyond the scope of this section.

Another way to obtain insights into a protein function is to look for protein with similar sequences or motifs.
Using BLAST, a sequence alignment tool, one can align two or more protein sequences and determine their level of similarity [@PMID:2231712].
For example, if a human protein of unknown function has a similar sequence to a yeast protein with known function this may be a starting place for the putative function of that protein.

Novel approaches to representing the similarity of proteins have proved successful at predicting the functional properties of proteins.
Protein language models seek to learn “representation” of proteins, these are usually numerical vectors that represent a protein sequence [@DOI:https://doi.org/10.1038/s42256-022-00457-9, @DOI10.1016/j.cels.2021.05.017].
Abstractly, these vectors preserve protein similarity or a notion of “proteinness”. This usually means that two proteins that have a close vector may share similarities in protein function.
These representations are also advantageous because they can easily become the inputs for machine learning algorithms to predict valuable protein properties; for example, thermal stability values [@PMID:32133759], protein-protein binding affinities [@https://doi.org/10.1002/wcms.1448], secondary protein structure and more [@DOI
https://doi.org/10.1073/pnas.201623911].

3. Orthogonal experimental methods
